from openai import OpenAI
import requests
import json
import time
import asyncio
from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
from pathlib import Path
import os
import uuid
from fastapi.middleware.cors import CORSMiddleware

# âœ… FastAPI ì´ˆê¸°í™”
app = FastAPI()

# âœ… CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# âœ… ì—…ë¡œë“œ í´ë” ì„¤ì •
UPLOAD_DIR = Path("uploads") if os.name == "nt" else Path("/tmp/uploads")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)




# âœ… OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
client = OpenAI(api_key="<your_OpenAI_API_key>")  # ğŸ”¹ OpenAI API í‚¤ ì…ë ¥

# âœ… Clova OCR API ì„¤ì •
CLOVA_API_URL = "<your_API_URL>"
CLOVA_SECRET_KEY = "<your_SECRET_KEY>"

# âœ… Clova OCR í˜¸ì¶œ í•¨ìˆ˜
def clova_ocr(image_path):
    headers = {"X-OCR-SECRET": CLOVA_SECRET_KEY}
    payload = {
        "version": "V2",
        "requestId": str(uuid.uuid4()),
        "timestamp": int(time.time() * 1000),
        "images": [{"format": image_path.suffix.replace(".", ""), "name": "ocr_image"}]
    }

    with open(image_path, "rb") as f:
        files = {"file": f}
        response = requests.post(CLOVA_API_URL, headers=headers, data={"message": json.dumps(payload)}, files=files)

    if response.status_code == 200:
        return response.json()
    else:
        return {"error": f"Request failed with status code {response.status_code}", "details": response.text}

# âœ… OCRì—ì„œ í…ìŠ¤íŠ¸ì™€ ì¢Œí‘œ ì¶”ì¶œ
def extract_text_and_positions(ocr_result):
    extracted_data = []
    
    if "images" in ocr_result:
        for image in ocr_result["images"]:
            if "fields" in image:
                for field in image["fields"]:
                    text = field["inferText"]
                    position = field["boundingPoly"]["vertices"][0]  # ì¢Œì¸¡ ìƒë‹¨ (ì²« ê¸€ì ì¢Œí‘œ)
                    extracted_data.append({"text": text, "x": position["x"], "y": position["y"]})

    return extracted_data

# âœ… GPTë¥¼ í™œìš©í•˜ì—¬ OCR ê²°ê³¼ë¥¼ JSONìœ¼ë¡œ ì •ì œ
def gpt_refine_text(extracted_data):
    prompt = f"""
    ë‹¤ìŒì€ OCRì„ í†µí•´ ì¶”ì¶œí•œ í…ìŠ¤íŠ¸ ë°ì´í„°ì…ë‹ˆë‹¤.  
    ëª¨ë“  ìœ í˜•ì˜ ë¬¸ì„œë¥¼ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•˜ì„¸ìš”.

    âœ… **ì¤‘ìš” ê·œì¹™ (í•„ìˆ˜ ì¤€ìˆ˜!)**
    - 1. OCRë¡œ ê°ì§€ëœ ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ìœ ì§€í•˜ì„¸ìš”. (ëˆ„ë½ ê¸ˆì§€!)
    - 2. ì˜ëª»ëœ ê³µë°±ì´ë‚˜ ë‹¨ì–´ê°€ í•©ì³ì§„ ê²½ìš° ìë™ ìˆ˜ì •í•˜ì„¸ìš”.
    - ì˜ˆ: `"ì§œì¥ ì†ŒìŠ¤"` â†’ `"ì§œì¥ì†ŒìŠ¤"` (âœ… ì˜¬ë°”ë¥¸ ë³‘í•©)  
    - ì˜ˆ: `"ê¹€ì¹˜ ë§Œë‘"` â†’ `"ê¹€ì¹˜ë§Œë‘"` (âœ… ì˜¬ë°”ë¥¸ ë³‘í•©)  
    - 3. ê° í•­ëª©ì— ì¢Œí‘œ(x, y)ë¥¼ í¬í•¨í•˜ì„¸ìš”. (ì ˆëŒ€ ëˆ„ë½ ê¸ˆì§€!)
    - 4. ë¬¸ì„œ ìœ í˜•ì„ ìë™ ê°ì§€í•˜ê³  ì˜¬ë°”ë¥¸ êµ¬ì¡°ë¡œ ì •ë¦¬í•˜ì„¸ìš”.
    - 5. ë©”ë‰´íŒì´ë¼ë©´ ê°€ê²©ì„ ì •í™•íˆ ë§¤ì¹­í•˜ê³ , ì„¤ëª…ì„œë¼ë©´ ë¶€í’ˆ ëª©ë¡ì„ êµ¬ë¶„í•˜ì„¸ìš”.
    - 6. ì›ë¬¸ê³¼ ë¹„êµí•˜ëŠ” ë°©ì‹ìœ¼ë¡œ ìš”ì²­í•˜ì—¬ ì˜ë¯¸ê°€ ë³€ê²½ë  ê²½ìš° ìˆ˜ì •í•˜ì§€ ë§ˆì„¸ìš”.
    - 7. ë¬¸ì¥ì˜ ì˜ë¯¸ê°€ ì—†ê±°ë‚˜ ì˜¤íƒ€ê°€ ì¡´ì¬ ì‹œ 6ë²ˆì„ ë¬´ì‹œí•˜ê³  ì„ì˜ë¡œ ë³€ê²½ í•˜ì„¸ìš”.
    

    **ğŸ“Œ ë¬¸ì„œ ìœ í˜• ìë™ ë¶„ë¥˜**
    1ï¸âƒ£ **ë©”ë‰´íŒ (`menu`)**
       - **ë©”ë‰´ëª…ê³¼ ê°€ê²©ì„ ì›ë³¸ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ì„¸ìš”.**
       - **ì¹´í…Œê³ ë¦¬ê°€ ìˆì„ ê²½ìš° ìœ ì§€, ì—†ìœ¼ë©´ ì œì™¸í•˜ì„¸ìš”.**
       - **ì¶”ê°€ ì •ë³´(í¬ì¥ ê°€ëŠ¥ ì—¬ë¶€, ì˜µì…˜ ë“±)ëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ ë”°ë¡œ ì •ë¦¬í•˜ì„¸ìš”.**
    
    2ï¸âƒ£ **ì„¤ëª…ì„œ (`manual`)**
       - **ì„¤ëª… ë¬¸ì¥ê³¼ ë¶€í’ˆ ëª©ë¡ì„ ë”°ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.**
    
    3ï¸âƒ£ **ì•ˆë‚´ë¬¸ (`notice`)**
       - **ë¬¸ì¥ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì •ë¦¬í•˜ì„¸ìš”.**

    OCR ê²°ê³¼:
    {json.dumps(extracted_data, ensure_ascii=False)}

    âœ… **ì¶œë ¥ í˜•ì‹ (JSON)**
    {{
      "document_type": "menu / manual / notice",
      "sections": [
        {{
          "type": "table",
          "headers": ["ë©”ë‰´", "ê°€ê²©"],
          "rows": [
            {{
              "data": ["ë©”ë‰´ëª…", "ê°€ê²©"],
              "coordinates": {{
                "x": xì¢Œí‘œ,
                "y": yì¢Œí‘œ
              }}
            }}
          ]
        }},
        {{
          "type": "list",
          "items": [
            {{
              "name": "ì¶”ê°€ ì •ë³´ ë¬¸êµ¬",
              "coordinates": {{
                "x": xì¢Œí‘œ,
                "y": yì¢Œí‘œ
              }}
            }}
          ]
        }},
        {{
          "type": "text",
          "content": "ì„¤ëª… ë¬¸ì¥",
          "coordinates": {{
            "x": xì¢Œí‘œ,
            "y": yì¢Œí‘œ
          }}
        }}
      ]
    }}
    """

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=[{"role": "user", "content": prompt}],
        response_format={"type": "json_object"}
    )

    return json.loads(response.choices[0].message.content)

# âœ… OpenAI GPT ìš”ì²­ì„ ë¹„ë™ê¸° ì²˜ë¦¬
async def gpt_refine_text_async(extracted_data):
    return await asyncio.to_thread(gpt_refine_text, extracted_data)

# âœ… FastAPI ì—”ë“œí¬ì¸íŠ¸
@app.post("/upload_and_refine/")
async def upload_and_refine(file: UploadFile = File(...)):
    unique_filename = f"{uuid.uuid4().hex}{Path(file.filename).suffix.lower()}"
    file_path = UPLOAD_DIR / unique_filename

    with file_path.open("wb") as buffer:
        buffer.write(await file.read())

    ocr_result = clova_ocr(file_path)
    extracted_data = extract_text_and_positions(ocr_result)

    if not extracted_data:
        return JSONResponse(content={"error": "No text found in the image.", "ocr_result": ocr_result})

    # âœ… OCR ê²°ê³¼ ì •ì œ ë° JSON ë³€í™˜
    refined_text = await gpt_refine_text_async(extracted_data)

    return JSONResponse(content={
        "filename": unique_filename,
        "original_filename": file.filename,
        "refined_text": refined_text,
        "message": "File uploaded, OCR processed, and text refined successfully"
    })

# âœ… FastAPI ì‹¤í–‰
if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
